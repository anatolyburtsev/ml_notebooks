{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install joblib six\n",
    "# !pip install 'gym[all]'\n",
    "# !pip install pyglet==1.2.4\n",
    "# !pip install pyvirtualdisplay\n",
    "# !pip install --no-cache-dir -I pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import numpy as np\n",
    "import scipy\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.animation as animation \n",
    "from IPython.core.debugger import set_trace\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch,actions_batch,rewards_batch,percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i][t]\n",
    "    \n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "    \n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "    \n",
    "    If you're confused, see examples below. Please don't assume that states are integers (they'll get different later).\n",
    "    \"\"\"\n",
    "    \n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    states_batch = np.array(states_batch)\n",
    "    actions_batch = np.array(actions_batch)\n",
    "    \n",
    "    elite_mask = rewards_batch > reward_threshold\n",
    "    elite_states  = states_batch[elite_mask]\n",
    "    elite_actions = actions_batch[elite_mask]\n",
    "#     set_trace()\n",
    "\n",
    "#     if elite_states != []:\n",
    "    elite_states = np.concatenate(elite_states)\n",
    "    elite_actions = np.concatenate(elite_actions)\n",
    "    \n",
    "    return elite_states,elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch,log):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "    \n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch,percentile)\n",
    "    log.append([mean_reward,threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\"%(mean_reward,threshold))\n",
    "    plt.figure(figsize=[8,4])\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(list(zip(*log))[0],label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1],label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.hist(rewards_batch,range=[min(rewards_batch), max(rewards_batch)]);\n",
    "    plt.vlines([np.percentile(rewards_batch,percentile)],[0],[100],label=\"percentile\",color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb54908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"MountainCar-v0\").env\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# plt.imshow(env.render(\"rgb_array\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(hidden_layer_sizes=(20,20),\n",
    "                      activation='tanh',\n",
    "                      warm_start=True, #keep progress between .fit(...) calls\n",
    "                      max_iter=1, #make only 1 iteration on each .fit(...)\n",
    "                     )\n",
    "\n",
    "#initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset()]*n_actions, range(n_actions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(t_max=10000):\n",
    "    states,actions = [],[]\n",
    "    total_rewards = 0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "        a = np.random.choice(n_actions, p=probs)\n",
    "        new_s, r, done, _ = env.step(a)\n",
    "        \n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_rewards += r\n",
    "        s = new_s[:]\n",
    "        if done: break\n",
    "    return states, actions, total_rewards\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_sessions = 100\n",
    "percentile = 90\n",
    "log = []\n",
    "epochs = 100\n",
    "value_to_stop = -200\n",
    "\n",
    "for i in range(epochs):\n",
    "    t = dt.now()\n",
    "    sessions = Parallel(n_jobs=4)(delayed(generate_session)() for _ in range(n_sessions))\n",
    "    \n",
    "#     sessions = [generate_session() for _ in range(n_sessions)]\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "    elite_states, elite_actions = select_elites(states_batch,\n",
    "                                                actions_batch,\n",
    "                                                rewards_batch,\n",
    "                                                percentile=percentile)\n",
    "\n",
    "    agent.fit(elite_states, elite_actions)\n",
    "    \n",
    "    show_progress(rewards_batch, log)\n",
    "    print(\"iteration time: {t} s\".format(t=(dt.now() - t).seconds))\n",
    "    if np.mean(rewards_batch) > value_to_stop:\n",
    "        print(\"You win\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
